{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar of personhood (machine learning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "I'm working on my personification chapter now. So far I've measured an [\"agency index\"](https://twitter.com/quadrismegistus/status/1059305496211931136), trying to find trends in how words gain/lose (syntactic) \"agency\" over time. This has been interesting, but what's missing is that personifications don't just do things (as the agency index captures), they do *human* things (\"let not Ambition *mock*\") and have *human* things (\"Honour's voice\").\n",
    "\n",
    "So I'm trying to move on from this 'syntax of agency' to a broader 'grammar of personhood'. I took a failed stopover at the 'semantics of personhood' via word2vec: my 'human words' vector didn't end up being that interesting an index for other words, i.e. didn't seem to capture personification effects. Now I'm moving back to the syntactic BookNLP-style data (subject-verb, modifier-noun, etc) I've collected about the nouns for the Chadwyck Healey poetry collections.\n",
    "\n",
    "I'm wondering whether a classifier to separate human vs. non-human (maybe human vs. object) words by way of the distribution of other words ('collocated' by syntax): and then use that classifier to estimate the 'humanness' of all words, not just those in the cross-validation experiment? I did this in a smaller related project on animal stories, and according to the cross-validation results, the model found it easier to separate humans and animals in novels than it did in these anthropomorphic animal stories, which seemed right. But here I want to use a classifier to estimate the humanness of all, even non-human/object words like abstract nouns, to see if that changes over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with this data (*data.booknlp_like_data.chadwyck_poetry.txt.gz*) to *data_booknlp/*\n",
    "Generated by [this notebook](BookNLP-like-Data.ipynb) on Sherlock.\n",
    "\n",
    "Data appears as:\n",
    "\n",
    "| fn             | head     | num_sent | rel      | word      |\n",
    "|----------------|----------|----------|----------|-----------|\n",
    "| Z400605772.xml | are      | 1        | nsubj    | hills     |\n",
    "| Z400605772.xml | knows    | 2        | dobj     | roads     |\n",
    "| Z400605772.xml | knows    | 2        | conj     | moves     |\n",
    "| Z400605772.xml | in       | 3        | pobj     | circles   |\n",
    "| Z400605772.xml | within   | 3        | pobj     | head      |\n",
    "| Z400605772.xml | has      | 4        | dobj     | say       |\n",
    "| Z400605772.xml | is       | 5        | nsubj    | river     |\n",
    "| Z400605772.xml | lie      | 5        | nsubj    | winds     |\n",
    "| Z400605772.xml | at       | 6        | pobj     | dawn      |\n",
    "| Z400605772.xml | sees     | 6        | dobj     | skies     |\n",
    "| Z400605772.xml | feels    | 7        | nsubj    | shadows   |\n",
    "| Z400605772.xml | of       | 7        | pobj     | night     |\n",
    "| Z400605772.xml | recline  | 7        | dobj     | fingers   |\n",
    "| Z400605772.xml | on       | 7        | pobj     | eyes      |\n",
    "| Z400605772.xml | welcomes | 8        | dobj     | sun       |\n",
    "| Z400605772.xml | sun      | 8        | conj     | rain      |\n",
    "| Z400605772.xml | has      | 9        | nsubj    | landscape |\n",
    "| Z400605772.xml | has      | 9        | dobj     | depth     |\n",
    "| Z400605772.xml | depth    | 9        | conj     | height    |\n",
    "| Z400605772.xml | city     | 10       | ROOT     | city      |\n",
    "| Z400605772.xml | burns    | 10       | compound | passion   |\n",
    "| Z400605772.xml | like     | 10       | pobj     | burns     |\n",
    "| Z400605772.xml | walks    | 11       | compound | morning   |\n",
    "| Z400605772.xml | of       | 11       | pobj     | walks     |\n",
    "| Z400605772.xml | on       | 11       | pobj     | wave      |\n",
    "| Z400605772.xml | of       | 11       | pobj     | sand      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning human nouns\n",
    "Code adapted from the classification work in the [Wild Animal Stories notebook](http://localhost:8888/lab/tree/workspace%2Fwildanimalstories%2Fexperiments.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> reading config files...\n",
      ">> streaming as tsv: /Users/ryan/DH/lit/corpus/chadwyck_poetry/corpus-metadata.ChadwyckPoetry.txt\n",
      "   done [2.9 seconds]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'Z200427100.xml', '1850-1874'),\n",
       " (u'Z200358033.xml', '1975-1999'),\n",
       " (u'Z400369280.xml', '1900-1924'),\n",
       " (u'Z300173395.xml', '1850-1874'),\n",
       " (u'Z200137391.xml', '1850-1874')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lit\n",
    "CP=lit.load_corpus('ChadwyckPoetry')\n",
    "CPgroups = CP.new_grouping()\n",
    "CPgroups.group_by_author_at_30(yearbin=25)\n",
    "CPgroups.prune_groups(min_group=1600,max_group=2000,min_len=10)\n",
    "fn2group=dict((k.split('/')[-1]+'.xml',v) for k,v in CPgroups.textid2group.items())\n",
    "fn2group.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lit import tools\n",
    "import os\n",
    "def transform_booknlp_like_data(fn='data_booknlp/data.booknlp_like_data.chadwyck_poetry.txt.gz',\n",
    "                                odir='data_booknlp/data_by_quarter_century/'):\n",
    "    \"\"\"\n",
    "    save booknlp-like data in separate files by group\n",
    "    \"\"\"\n",
    "    if not os.path.exists(odir): os.makedirs(odir)\n",
    "    group2f={}\n",
    "    header=None\n",
    "    for dx in tools.readgen(fn):\n",
    "        if not header: header=sorted(list(dx.keys()))\n",
    "        group=fn2group.get(dx['fn'])\n",
    "        if not group: continue\n",
    "        dx['group']=group\n",
    "        ofn=os.path.join(odir,group+'.txt')\n",
    "        import codecs\n",
    "        if not group in group2f:\n",
    "            f=group2f[group]=codecs.open(ofn,'w',encoding='utf-8')\n",
    "            f.write('\\t'.join(h for h in header) + '\\n')\n",
    "        f=group2f[group]\n",
    "        f.write('\\t'.join(dx.get(h,'') for h in header) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform_booknlp_like_data()\n",
    "\n",
    "#transform_booknlp_like_data(fn='data_booknlp/data.booknlp_like_data.chadwyck_poetry.lemmatized.txt.gz',\n",
    "#                            odir='data_booknlp/data_by_quarter_century_lemmatized/')\n",
    "# last run (V2, lemmatized): 2/5/19 03:34 [I couldn't sleep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDS_WANTED = ['VG.Human','VG.Object','VG.Animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> streaming as tsv: /Users/ryan/DH/Dissertation/abstraction/words/data.fields.txt\n",
      "   done [0.1 seconds]\n"
     ]
    }
   ],
   "source": [
    "from lit.tools.freqs import get_fields\n",
    "import pandas as pd\n",
    "fields=get_fields()\n",
    "#fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> VG.Human 395\n",
      ">> VG.Object 661\n",
      ">> VG.Animal 82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'peacock', 'VG.Animal'),\n",
       " (u'coach', 'VG.Human'),\n",
       " (u'liar', 'VG.Human'),\n",
       " (u'rabbit', 'VG.Animal'),\n",
       " (u'corps', 'VG.Human'),\n",
       " (u'fox', 'VG.Animal'),\n",
       " (u'bull', 'VG.Animal'),\n",
       " (u'dollar', 'VG.Object'),\n",
       " (u'commoner', 'VG.Human'),\n",
       " (u'obstruction', 'VG.Object'),\n",
       " (u'manager', 'VG.Human'),\n",
       " (u'pervert', 'VG.Human'),\n",
       " (u'gang', 'VG.Human'),\n",
       " (u'zinc', 'VG.Object'),\n",
       " (u'skin', 'VG.Object'),\n",
       " (u'aristocrat', 'VG.Human'),\n",
       " (u'chair', 'VG.Object'),\n",
       " (u'captain', 'VG.Human'),\n",
       " (u'milk', 'VG.Object'),\n",
       " (u'equipment', 'VG.Object'),\n",
       " (u'voter', 'VG.Human'),\n",
       " (u'grape', 'VG.Object'),\n",
       " (u'buddy', 'VG.Human'),\n",
       " (u'pioneer', 'VG.Human'),\n",
       " (u'gymnast', 'VG.Human')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2field={}\n",
    "for field in FIELDS_WANTED:\n",
    "    field_words=fields.get(field,[])\n",
    "    print '>>',field,len(field_words)\n",
    "    for word in field_words:\n",
    "        word2field[word]=field\n",
    "\n",
    "word2field.items()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of these from spacy: https://spacy.io/api/annotation\n",
    "# spacy uses the ClearNLP tags for English:\n",
    "# https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "\n",
    "rels = {\n",
    "    'poss':'Possessive',\n",
    "    'nsubj':'Subject',\n",
    "    'nsubjpass':'Subject (passive)',\n",
    "    'dobj':'Object (direct)',\n",
    "    'amod':'Modifier (adjective)',\n",
    "    #'compound':'Modifier (noun->noun)',\n",
    "    #'appos':'Modifier (noun<-noun)',\n",
    "    #'attr':'Modifier (predicate?)',   # not in universal schema\n",
    "    'dative':'Object (indirect)'       # not in universal schema [instead, \"iobj\"]\n",
    "}\n",
    "\n",
    "rel_is_backwards = {'amod'}            # these rels put the head on the non-noun as opposed to others\n",
    "\n",
    "REL_WORD = True  # True for rel_word ('dobj_roads') or False for word (just 'roads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within groups, start classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_group_file(fn='data_booknlp/data_by_quarter_century/1600-1624.txt',only_rels=rels,only_fields=True):\n",
    "    import pandas as pd\n",
    "    df=pd.read_csv(fn,sep='\\t',encoding='utf-8',quoting=3,error_bad_lines=False)\n",
    "    \n",
    "    if only_rels: df=df.loc[df.rel.isin(rels)]\n",
    "    df['field']=[word2field.get(w,'') for w in df.word]\n",
    "    if only_fields: df=df.loc[df.field!='']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>head</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>rel</th>\n",
       "      <th>word</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Z200410536.xml</td>\n",
       "      <td>attempt</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>man</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Z200410536.xml</td>\n",
       "      <td>assay</td>\n",
       "      <td>15</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>foe</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Z200410536.xml</td>\n",
       "      <td>lift</td>\n",
       "      <td>17</td>\n",
       "      <td>poss</td>\n",
       "      <td>hand</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Z200410536.xml</td>\n",
       "      <td>act</td>\n",
       "      <td>17</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>hand</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Z300448748.xml</td>\n",
       "      <td>gainst</td>\n",
       "      <td>1</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>finger</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fn     head  num_sent    rel    word      field\n",
       "9   Z200410536.xml  attempt         5  nsubj     man   VG.Human\n",
       "22  Z200410536.xml    assay        15  nsubj     foe   VG.Human\n",
       "26  Z200410536.xml     lift        17   poss    hand  VG.Object\n",
       "28  Z200410536.xml      act        17  nsubj    hand  VG.Object\n",
       "85  Z300448748.xml   gainst         1  nsubj  finger  VG.Object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = open_group_file()\n",
    "df = open_group_file(fn='data_booknlp/data_by_quarter_century_lemmatized/1600-1624.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'nsubj'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,row=df.iterrows().next()\n",
    "row['rel']\n",
    "#list(df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_crosstabs(df,lim_cols=2000,row_sum_min=10,syntax=False,rel_word=REL_WORD):\n",
    "    if rel_word:\n",
    "        df['rel_head']=[unicode(row.get('rel',''))+'_'+unicode(row.get('head','')) for row in df.to_dict('records')]\n",
    "        #dfc=pd.crosstab(df['word'],df['rel_head'])\n",
    "\n",
    "        # @new --> leave in rel's by themselves too -->\n",
    "        left=pd.crosstab(df['word'], df['rel_head'])\n",
    "        right=pd.crosstab(df['word'], df['rel'])\n",
    "        dfc=left.join(right,rsuffix='_rel')\n",
    "    else:\n",
    "        left=pd.crosstab(df['word'], df['head'])\n",
    "        right=pd.crosstab(df['word'], df['rel'])\n",
    "        dfc=left.join(right,rsuffix='_rel')\n",
    "\n",
    "    dfc=dfc.loc[dfc.sum(axis=1)>row_sum_min]\n",
    "    cols=list(dfc.sum(axis=0).nlargest(lim_cols).index)\n",
    "    dfc=dfc[cols]\n",
    "    ## add field\n",
    "    dfc['_field']=[word2field.get(w,'') for w in dfc.index]\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsubj</th>\n",
       "      <th>dobj</th>\n",
       "      <th>nsubj_be</th>\n",
       "      <th>nsubjpass</th>\n",
       "      <th>poss</th>\n",
       "      <th>...</th>\n",
       "      <th>nsubj_unfeign</th>\n",
       "      <th>nsubj_unto</th>\n",
       "      <th>nsubj_wall</th>\n",
       "      <th>nsubj_weal</th>\n",
       "      <th>_field</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acquaintance</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversary</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambassador</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancestor</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arch</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arm</th>\n",
       "      <td>247</td>\n",
       "      <td>270</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrow</th>\n",
       "      <td>66</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>833</td>\n",
       "      <td>409</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ash</th>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ass</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assembly</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>98</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>axe</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bachelor</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag</th>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bale</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ball</th>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barrel</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basket</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bastard</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bat</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bath</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bay</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beard</th>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villain</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vulture</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiter</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>105</td>\n",
       "      <td>190</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ward</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wardrobe</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrant</th>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrior</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>347</td>\n",
       "      <td>190</td>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wave</th>\n",
       "      <td>147</td>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wax</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weapon</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weed</th>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wench</th>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wheat</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wheel</th>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whip</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>395</td>\n",
       "      <td>292</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>67</td>\n",
       "      <td>107</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>108</td>\n",
       "      <td>249</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wire</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witch</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolf</th>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>425</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>32</td>\n",
       "      <td>246</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womb</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>68</td>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>213</td>\n",
       "      <td>158</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nsubj  dobj  nsubj_be  nsubjpass  poss    ...      \\\n",
       "word                                                    ...       \n",
       "acquaintance     19    24         3          1     0    ...       \n",
       "actor             9     3         1          1     0    ...       \n",
       "adversary        30     4         8          2     0    ...       \n",
       "ambassador        4     5         1          0     0    ...       \n",
       "ancestor         22     7         6          0     0    ...       \n",
       "anchor           17     7         0          3     0    ...       \n",
       "ant               6     2         0          0     0    ...       \n",
       "arch              3    10         1          0     0    ...       \n",
       "arm             247   270        24         29     2    ...       \n",
       "arrow            66    40         4          2     0    ...       \n",
       "art             833   409        55         26     7    ...       \n",
       "artist           11     4         2          0     2    ...       \n",
       "ash              53    28         5          6     0    ...       \n",
       "ass              13    13         2          2     0    ...       \n",
       "assembly         11     2         4          0     0    ...       \n",
       "author           98    27        18          3     1    ...       \n",
       "axe               8     5         0          5     0    ...       \n",
       "baby              3     4         0          0     0    ...       \n",
       "bachelor          6     0         0          0     0    ...       \n",
       "bag              21    39         3          1     0    ...       \n",
       "bale              2     4         0          0     0    ...       \n",
       "ball             19    29         2          0     0    ...       \n",
       "bar              18    31         5          1     0    ...       \n",
       "barrel            4     6         1          0     1    ...       \n",
       "basket            9     4         0          2     0    ...       \n",
       "bastard           6     3         3          0     0    ...       \n",
       "bat               4     5         1          1     0    ...       \n",
       "bath              6     4         1          0     0    ...       \n",
       "bay               4    14         0          0     0    ...       \n",
       "beard            31    37         7          3     0    ...       \n",
       "...             ...   ...       ...        ...   ...    ...       \n",
       "villain          30     9         5          1     0    ...       \n",
       "viper            14     4         3          0     0    ...       \n",
       "vulture          13     2         0          0     0    ...       \n",
       "waiter            6     0         1          0     0    ...       \n",
       "wall            105   190        18         15     0    ...       \n",
       "ward              9    14         2          0     0    ...       \n",
       "wardrobe          5     4         0          0     0    ...       \n",
       "warrant          16    31         2          1     0    ...       \n",
       "warrior           6     4         3          0     0    ...       \n",
       "water           347   190        46         17     2    ...       \n",
       "wave            147   113        12         10     1    ...       \n",
       "wax              17    14         1          2     0    ...       \n",
       "weapon           60    55         6          1     0    ...       \n",
       "weed             40    61         3          6     0    ...       \n",
       "wench            43    30         5          0     0    ...       \n",
       "wheat             8    13         2          1     0    ...       \n",
       "wheel            40    60         3         10     0    ...       \n",
       "whip             22    33         2          1     0    ...       \n",
       "wife            395   292        61         19     8    ...       \n",
       "wine             67   107        12          6     0    ...       \n",
       "wing            108   249         9         25     2    ...       \n",
       "wire              2     4         1          0     0    ...       \n",
       "witch            11     7         2          0     0    ...       \n",
       "wolf             34    39         3          3     0    ...       \n",
       "woman           425   103        87         32   246    ...       \n",
       "womb             60    61         7          3     0    ...       \n",
       "wood             68   115        10          7     0    ...       \n",
       "worker           11     6         6          2     0    ...       \n",
       "writer           31     4         2          2     1    ...       \n",
       "youth           213   158        23         21     8    ...       \n",
       "\n",
       "              nsubj_unfeign  nsubj_unto  nsubj_wall  nsubj_weal     _field  \n",
       "word                                                                        \n",
       "acquaintance              0           0           0           0   VG.Human  \n",
       "actor                     0           0           0           0   VG.Human  \n",
       "adversary                 0           0           0           0   VG.Human  \n",
       "ambassador                0           0           0           0   VG.Human  \n",
       "ancestor                  0           0           0           0   VG.Human  \n",
       "anchor                    0           0           0           0  VG.Object  \n",
       "ant                       0           0           0           0  VG.Animal  \n",
       "arch                      0           0           0           0  VG.Object  \n",
       "arm                       0           0           0           0  VG.Object  \n",
       "arrow                     0           0           0           0  VG.Object  \n",
       "art                       0           0           0           0  VG.Object  \n",
       "artist                    0           0           0           0   VG.Human  \n",
       "ash                       0           0           0           0  VG.Object  \n",
       "ass                       0           0           0           0  VG.Object  \n",
       "assembly                  0           0           0           0   VG.Human  \n",
       "author                    0           0           0           0   VG.Human  \n",
       "axe                       0           0           0           0  VG.Object  \n",
       "baby                      0           0           0           0   VG.Human  \n",
       "bachelor                  0           0           0           0   VG.Human  \n",
       "bag                       0           0           0           0  VG.Object  \n",
       "bale                      0           0           0           0  VG.Object  \n",
       "ball                      0           0           0           0  VG.Object  \n",
       "bar                       0           0           0           0  VG.Object  \n",
       "barrel                    0           0           0           0  VG.Object  \n",
       "basket                    0           0           0           0  VG.Object  \n",
       "bastard                   0           0           0           0   VG.Human  \n",
       "bat                       0           0           0           0  VG.Animal  \n",
       "bath                      0           0           0           0  VG.Object  \n",
       "bay                       0           0           0           0  VG.Object  \n",
       "beard                     0           0           0           0  VG.Object  \n",
       "...                     ...         ...         ...         ...        ...  \n",
       "villain                   0           0           0           0   VG.Human  \n",
       "viper                     0           0           0           0  VG.Animal  \n",
       "vulture                   0           0           0           0  VG.Animal  \n",
       "waiter                    0           0           0           0   VG.Human  \n",
       "wall                      0           0           0           0  VG.Object  \n",
       "ward                      0           0           0           0  VG.Object  \n",
       "wardrobe                  0           0           0           0  VG.Object  \n",
       "warrant                   0           0           0           0  VG.Object  \n",
       "warrior                   0           0           0           0   VG.Human  \n",
       "water                     0           0           1           0  VG.Object  \n",
       "wave                      0           0           2           0  VG.Object  \n",
       "wax                       0           0           0           0  VG.Object  \n",
       "weapon                    0           0           0           0  VG.Object  \n",
       "weed                      0           0           0           0  VG.Object  \n",
       "wench                     0           0           0           0   VG.Human  \n",
       "wheat                     0           0           0           0  VG.Object  \n",
       "wheel                     0           0           0           0  VG.Object  \n",
       "whip                      0           0           0           0  VG.Object  \n",
       "wife                      0           0           0           0   VG.Human  \n",
       "wine                      0           0           0           0  VG.Object  \n",
       "wing                      0           0           0           0  VG.Object  \n",
       "wire                      0           0           0           0  VG.Object  \n",
       "witch                     0           0           0           0   VG.Human  \n",
       "wolf                      0           0           0           0  VG.Animal  \n",
       "woman                     0           0           0           0   VG.Human  \n",
       "womb                      0           0           0           0  VG.Object  \n",
       "wood                      0           0           0           0  VG.Object  \n",
       "worker                    0           0           0           0   VG.Human  \n",
       "writer                    0           0           0           0   VG.Human  \n",
       "youth                     0           0           0           0   VG.Human  \n",
       "\n",
       "[556 rows x 2001 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc=make_crosstabs(df)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsubj</th>\n",
       "      <th>dobj</th>\n",
       "      <th>nsubj_be</th>\n",
       "      <th>nsubjpass</th>\n",
       "      <th>poss</th>\n",
       "      <th>dobj_have</th>\n",
       "      <th>nsubj_do</th>\n",
       "      <th>...</th>\n",
       "      <th>nsubj_toil</th>\n",
       "      <th>nsubj_true</th>\n",
       "      <th>nsubj_unfeign</th>\n",
       "      <th>nsubj_unto</th>\n",
       "      <th>nsubj_wall</th>\n",
       "      <th>nsubj_weal</th>\n",
       "      <th>_field</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acquaintance</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversary</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambassador</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancestor</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womb</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>68</td>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>213</td>\n",
       "      <td>158</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VG.Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nsubj  dobj  nsubj_be  nsubjpass  poss  dobj_have  nsubj_do  \\\n",
       "word                                                                        \n",
       "acquaintance     19    24         3          1     0          2         0   \n",
       "actor             9     3         1          1     0          1         0   \n",
       "adversary        30     4         8          2     0          0         0   \n",
       "ambassador        4     5         1          0     0          0         0   \n",
       "ancestor         22     7         6          0     0          3         0   \n",
       "...             ...   ...       ...        ...   ...        ...       ...   \n",
       "womb             60    61         7          3     0          3         2   \n",
       "wood             68   115        10          7     0          1         0   \n",
       "worker           11     6         6          2     0          0         0   \n",
       "writer           31     4         2          2     1          1         3   \n",
       "youth           213   158        23         21     8          4        12   \n",
       "\n",
       "                ...      nsubj_toil  nsubj_true  nsubj_unfeign  nsubj_unto  \\\n",
       "word            ...                                                          \n",
       "acquaintance    ...               0           0              0           0   \n",
       "actor           ...               0           0              0           0   \n",
       "adversary       ...               0           0              0           0   \n",
       "ambassador      ...               0           0              0           0   \n",
       "ancestor        ...               0           0              0           0   \n",
       "...             ...             ...         ...            ...         ...   \n",
       "womb            ...               0           0              0           0   \n",
       "wood            ...               0           0              0           0   \n",
       "worker          ...               0           0              0           0   \n",
       "writer          ...               0           0              0           0   \n",
       "youth           ...               0           0              0           0   \n",
       "\n",
       "              nsubj_wall  nsubj_weal     _field  \n",
       "word                                             \n",
       "acquaintance           0           0   VG.Human  \n",
       "actor                  0           0   VG.Human  \n",
       "adversary              0           0   VG.Human  \n",
       "ambassador             0           0   VG.Human  \n",
       "ancestor               0           0   VG.Human  \n",
       "...                  ...         ...        ...  \n",
       "womb                   0           0  VG.Object  \n",
       "wood                   0           0  VG.Object  \n",
       "worker                 0           0   VG.Human  \n",
       "writer                 0           0   VG.Human  \n",
       "youth                  0           0   VG.Human  \n",
       "\n",
       "[556 rows x 2001 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 15\n",
    "pd.options.display.max_rows = 10\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def classify(X,y):\n",
    "    loo=LeaveOneOut()\n",
    "    correct=[]\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        clf = LogisticRegression(C=0.001)\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        clf.fit(X_train,y_train)\n",
    "        predictions=clf.predict(X_test)\n",
    "        correct+=[int(y_test[0]==predictions[0])]\n",
    "    return np.mean(correct)\n",
    "\n",
    "from scipy.stats import zscore\n",
    "def do_classification(df,target='_field',numruns=30,numsample=50,replace=False):\n",
    "    target_types=set(list(df[target]))\n",
    "    \n",
    "    objects=[]\n",
    "    for tt1 in target_types:\n",
    "        for tt2 in target_types:\n",
    "            if tt2<=tt1: continue\n",
    "            for nr in range(numruns):\n",
    "                objects+=[(tt1,tt2,nr)]\n",
    "    \n",
    "    import random\n",
    "    random.shuffle(objects)\n",
    "    numobj=len(objects)\n",
    "    for i,(tt1,tt2,nr) in enumerate(objects):\n",
    "        print i,numobj,tt1,tt2,nr,\n",
    "        dfs=[df.loc[df[target]==tt] for tt in [tt1,tt2]]\n",
    "        lens=[len(_df.index) for _df in dfs]\n",
    "        minlen=min(lens)\n",
    "        print lens,minlen,\n",
    "        ns=numsample if numsample else minlen\n",
    "        print ns,\n",
    "        try:\n",
    "            dfs_sample=[_df.sample(ns,replace=replace) for _df in dfs]\n",
    "        except ValueError:\n",
    "            print \"!!\"\n",
    "            continue\n",
    "        \n",
    "        ndf=pd.concat(dfs_sample)\n",
    "        Xdf=ndf.select_dtypes('number').apply(zscore).dropna(1)\n",
    "        y=np.array([word2field[w] for w in Xdf.index])\n",
    "        X=Xdf.values\n",
    "        \n",
    "        acc=classify(X,y)\n",
    "        print acc\n",
    "        odx={'class1':tt1,'class2':tt2,'accuracy':acc,'numruns':numruns,'numrun':nr,'numsample':numsample}\n",
    "        #print odx\n",
    "        yield odx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_group_file(fn='data_booknlp/data_by_quarter_century/1600-1624.txt',\n",
    "                        only_rels=rels,only_fields=True,\n",
    "                        numruns=30,lim_cols=2000):\n",
    "    df=open_group_file(fn=fn,only_rels=only_rels,only_fields=only_fields)\n",
    "    df_tabs=make_crosstabs(df,lim_cols=lim_cols)\n",
    "    for odx in do_classification(df_tabs,numruns=numruns):\n",
    "        odx['fn']=os.path.basename(fn)\n",
    "        odx['period_int']=fn.split('-')[0]\n",
    "        yield odx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 90 VG.Animal VG.Human 21 [39, 158] 39 50 !!\n",
      "1 90 VG.Animal VG.Object 19 [39, 359] 39 50 !!\n",
      "2 90 VG.Human VG.Object 5 [158, 359] 158 50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/anaconda2/lib/python2.7/site-packages/scipy/stats/stats.py:2253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75,\n",
       " 'class1': 'VG.Human',\n",
       " 'class2': 'VG.Object',\n",
       " 'fn': '1600-1624.txt',\n",
       " 'numrun': 5,\n",
       " 'numruns': 30,\n",
       " 'numsample': 50,\n",
       " 'period_int': 'data_booknlp/data_by_quarter_century_lemmatized/1600'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify_group_file().next()\n",
    "classify_group_file(fn='data_booknlp/data_by_quarter_century_lemmatized/1600-1624.txt').next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_classify_group_file(fn):\n",
    "    return list(classify_group_file(fn))\n",
    "\n",
    "def classify_all(idir='data_booknlp/data_by_quarter_century_lemmatized',lim_cols=2000):\n",
    "    import multiprocessing as mp\n",
    "    pool=mp.Pool()\n",
    "    filenames = [os.path.join(idir,fn) for fn in os.listdir(idir) if fn.endswith('.txt')]\n",
    "    for old in pool.imap_unordered(do_classify_group_file, filenames):\n",
    "        for odx in old:\n",
    "            yield odx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools.writegen('data_booknlp/data.classification_results.txt', classify_all)\n",
    "# last run, V2 (with normalization), 2/4/19 15:09\n",
    "\n",
    "#tools.writegen('data_booknlp/data.classification_results.txt', classify_all)\n",
    "# last run, V3 (with rel_word), 2/4/19 16:15\n",
    "\n",
    "#tools.writegen('data_booknlp/data.classification_results.v4-with-lemma.txt', classify_all)\n",
    "# last run, V4 (with rel_word and lemma), 2/5/19 11:02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for graphs...\n",
    "WIDTH=600\n",
    "from IPython.display import display, Image\n",
    "def show(fn,width=WIDTH):\n",
    "    return display(Image(fn,width=width))\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy looks ok?\n",
    "These are all binary classification problems. Thirty times (numruns) per quarter-century, predicting between 50 words (numsamples) of class1 and 50 words of class2, *without* standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show('images/Accuracy for predicting humananimalobject, 1600-2000.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy gets worse when we turn on standardization (Z-score) for features. Why? [V2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show('images/Accuracy for predicting humananimalobject, 1600-2000.V2 with standardization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy marginally better when \"rel_head\" (eg *nsubj_knows*) is used [V3], i.e. and not just \"head\" (eg knows). (Z-scores used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show('images/Accuracy for predicting humananimalobject, 1600-2000.V3 with rel_word.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy slightly worse when rel_lemma used not rel_word [V4] (as well as adding back in just the rel's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show('images/Accuracy for predicting humananimalobject, 1600-2000 -- V4 with lemma.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Median accuracy at the end of the day: **75%**, Human-vs-Object. Is that good enough to justify the next step?\n",
    "\n",
    "This is V3, without lemmatization. Results slightly worse for V4 (median 72%, with lemmatization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('images/Median accuracy rates per classification task (across all runs of all periods).png',width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show('images/Median accuracy rates per classification task (across all runs of all periods) -- V4 with lemma.png',width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step: estimating humanness\n",
    "\n",
    "Here we applying this machine-learnt model (separating human and objects) to estimate the 'humanness' of all other words in the data. We're not concerned with whether these estimations are “right,” per se, but more in the pattern of their wrongness: the word “nature” is not a person, but is there a history to its person-likeness? Is “nature” ever... dare I say... anthropomorphic: human-*like*, according to the model?\n",
    "\n",
    "\n",
    "### Saving doc-term matrices\n",
    "\n",
    "First let's save the document-term matrix of raw counts for each quarter-century, limited to the **lim_cols** most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save crosstabs\n",
    "CT_IDIR = 'data_booknlp/data_by_quarter_century/1600-1624.txt'\n",
    "CT_ODIR = 'data_booknlp/data_by_quarter_century__crosstabs' if not REL_WORD else 'data_booknlp/data_by_quarter_century__crosstabs__rel_word2'\n",
    "def save_crosstabs(fn=CT_IDIR,odir=CT_ODIR,\n",
    "                    only_rels=rels,field1='VG.Human',field2='VG.Object',\n",
    "                    row_sum_min=10,lim_cols=2000,rel_word=REL_WORD):\n",
    "    df=pd.read_csv(fn,sep='\\t',encoding='utf-8',quoting=3,error_bad_lines=False)\n",
    "    \n",
    "    if only_rels: df=df.loc[df.rel.isin(rels)]\n",
    "    df['field']=[word2field.get(w,'') for w in df.word]\n",
    "    #df=df.loc[df.field.isin({field1,field2})]\n",
    "    \n",
    "    ## make crosstabs\n",
    "    if rel_word:\n",
    "        print '>> crosstabbing rel_head counts',tools.now()\n",
    "        df['rel_head']=[unicode(row.get('rel',''))+'_'+unicode(row.get('head','')) for row in df.to_dict('records')]\n",
    "        counts_rel_head=pd.crosstab(df['word'],df['rel_head'])\n",
    "        print '>> crosstabbing rel counts',tools.now()\n",
    "        counts_rel=pd.crosstab(df['word'], df['rel'])\n",
    "        print '>> joining tables',tools.now()\n",
    "        df_tabs=counts_rel_head.join(counts_rel,rsuffix='_rel')\n",
    "    else:\n",
    "        print '>> crosstabbing head counts',tools.now()\n",
    "        counts_head=pd.crosstab(df['word'], df['head'])\n",
    "        print '>> crosstabbing rel counts',tools.now()\n",
    "        counts_rel=pd.crosstab(df['word'], df['rel'])\n",
    "        print '>> joining tables',tools.now()\n",
    "        df_tabs=counts_head.join(counts_rel,rsuffix='_rel')\n",
    "    print '>> filtering by row_sum_min',tools.now()\n",
    "    if row_sum_min: df_tabs=df_tabs.loc[df_tabs.sum(axis=1)>row_sum_min]\n",
    "    print '>> filtering by lim_cols',tools.now()\n",
    "    if lim_cols:\n",
    "        cols=list(df_tabs.sum(axis=0).nlargest(lim_cols).index)\n",
    "        df_tabs=df_tabs[cols]\n",
    "    ## add field\n",
    "    print '>> adding new column',tools.now()\n",
    "    df_tabs['_field']=[word2field.get(w,'') for w in df_tabs.index]\n",
    "    \n",
    "    if not os.path.exists(odir): os.makedirs(odir)\n",
    "    ofnfn=os.path.join(odir, os.path.basename(fn))\n",
    "    print '>> saving',tools.now()\n",
    "    df_tabs.to_csv(ofnfn,sep='\\t',encoding='utf-8')\n",
    "    print '>> saved:',ofnfn,tools.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_crosstabs(idir='data_booknlp/data_by_quarter_century/',\n",
    "                       odir='data_booknlp/data_by_quarter_century__crosstabs__rel_word/'):\n",
    "    ifiles = [os.path.join(idir,ifn) for ifn in os.listdir(idir) if ifn.endswith('.txt')]\n",
    "    tools.crunch(ifiles, save_crosstabs, kwargs={'odir':odir})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_all_crosstabs(idir='data_booknlp/data_by_quarter_century_lemmatized/',\n",
    "#                   odir='data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/')\n",
    "# v4, with lemma, 2/5 ~11:30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math,os\n",
    "from lit import tools\n",
    "from scipy.stats import zscore\n",
    "def classify_from_crosstabs(fn='data_booknlp/data_by_quarter_century__crosstabs__rel_word/1900-1924.txt',\n",
    "                    odir='data_booknlp/data_by_quarter_century__model_results/',\n",
    "                    field1='VG.Human',field2='VG.Object',target='_field',\n",
    "                    lim_cols=1000):\n",
    "    df_tabs=pd.read_csv(fn,sep='\\t',encoding='utf-8',quoting=3,error_bad_lines=False).fillna('').set_index('word')\n",
    "    #return None,df_tabs\n",
    "    \n",
    "    word2field=dict(zip(df_tabs.index,df_tabs[target]))\n",
    "    word2count=df_tabs.sum(axis=1)\n",
    "    word2rank=word2count.rank(axis=0,ascending=False)\n",
    "    word2count,word2rank=word2count.to_dict(),word2rank.to_dict()\n",
    "    \n",
    "    #from collections import Counter\n",
    "    #return Counter(word2count).most_common(),sorted(word2rank.items(),key=lambda xx: xx[1])\n",
    "    \n",
    "    #if lim_cols:\n",
    "    #    cols=df_tabs.select_dtypes('number').sum(axis=0).nlargest(lim_cols).index\n",
    "    #    df_tabs=df_tabs[list(cols) + ['_field']]\n",
    "    \n",
    "    ### make test and training sets\n",
    "    df_train = df_tabs.loc[df_tabs._field.isin({field1,field2})]\n",
    "    df_test = df_tabs.loc[~df_tabs._field.isin({field1,field2})]\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(C=0.001)\n",
    "    \n",
    "    # Fit\n",
    "    X_train=df_train.select_dtypes('number').apply(zscore).dropna(1) #.values\n",
    "    y_train=[word2field[w] for w in X_train.index]\n",
    "    clf.fit(X_train.values,y_train)\n",
    "    \n",
    "    # Save model results\n",
    "    if not os.path.exists(odir): os.makedirs(odir)\n",
    "    ofnfn=os.path.join(odir,os.path.basename(fn))\n",
    "    \n",
    "    df_feats = pd.DataFrame(clf.coef_).T\n",
    "    df_feats.columns = ['coeff']\n",
    "    df_feats['feat']=X_train.columns\n",
    "    counts=df_feats['count']=[sum(df_tabs[feat]) for feat in df_feats['feat']]\n",
    "\n",
    "    # this should be in descending order already\n",
    "    assert not False in [a>=b for a,b in tools.bigrams(counts)]\n",
    "    df_feats['rank']=[i+1 for i in range(len(df_feats))]\n",
    "    #df_feats.set_index('feat',inplace=True)\n",
    "    df_feats.to_csv(ofnfn,sep='\\t',encoding='utf-8')\n",
    "    print '>> saved:',ofnfn\n",
    "    \n",
    "    # Predict\n",
    "    X = df_tabs.select_dtypes('number').apply(zscore).dropna(1)\n",
    "    X = X[X_train.columns]\n",
    "    predictions=clf.predict_proba(X.values)\n",
    "    n_dim = len(predictions[0])\n",
    "    header=[('ProbClass%s' % (i+1)) for i in range(n_dim)]\n",
    "    df_result=pd.DataFrame(predictions, columns=header)\n",
    "    df_result['word']=df_tabs.index\n",
    "    #df_result=df_result.set_index('word')\n",
    "    df_result['word_count']=[word2count.get(w,'') for w in df_tabs.index]\n",
    "    df_result['word_rank']=[word2rank.get(w,'') for w in df_tabs.index]\n",
    "    return df_feats,df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1900-1924.txt\n"
     ]
    }
   ],
   "source": [
    "#df_feats,df_result=classify_from_crosstabs()\n",
    "df_feats,df_result=classify_from_crosstabs(fn='data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1900-1924.txt')\n",
    "#df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which features indicate HUMANs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>feat</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>-0.023929</td>\n",
       "      <td>poss_man</td>\n",
       "      <td>55</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-0.023706</td>\n",
       "      <td>dobj_help</td>\n",
       "      <td>106</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.022345</td>\n",
       "      <td>nsubj_take</td>\n",
       "      <td>1281</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>-0.021886</td>\n",
       "      <td>nsubj_bid</td>\n",
       "      <td>41</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>-0.019875</td>\n",
       "      <td>poss_home</td>\n",
       "      <td>46</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coeff        feat  count  rank\n",
       "868  -0.023929    poss_man     55   869\n",
       "485  -0.023706   dobj_help    106   486\n",
       "31   -0.022345  nsubj_take   1281    32\n",
       "1104 -0.021886   nsubj_bid     41  1105\n",
       "1008 -0.019875   poss_home     46  1009"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feats.sort_values(by='coeff',ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which features indicate OBJECTs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>feat</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.019847</td>\n",
       "      <td>dobj_pick</td>\n",
       "      <td>548</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.015865</td>\n",
       "      <td>dobj_use</td>\n",
       "      <td>362</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.015278</td>\n",
       "      <td>dobj_wear</td>\n",
       "      <td>425</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.014652</td>\n",
       "      <td>dobj_read</td>\n",
       "      <td>779</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.014332</td>\n",
       "      <td>dobj_pull</td>\n",
       "      <td>296</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coeff       feat  count  rank\n",
       "103  0.019847  dobj_pick    548   104\n",
       "143  0.015865   dobj_use    362   144\n",
       "128  0.015278  dobj_wear    425   129\n",
       "65   0.014652  dobj_read    779    66\n",
       "177  0.014332  dobj_pull    296   178"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feats.sort_values(by='coeff',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_from_crosstabs(idir=None):\n",
    "    paths = [os.path.join(idir,fn) for fn in sorted(os.listdir(idir)) if fn.endswith('.txt')]\n",
    "    for path in paths:\n",
    "        print '>>',path\n",
    "        df_feats,df_result=classify_from_crosstabs(path)\n",
    "        ld_result = df_result.to_dict('records')\n",
    "        for dx in ld_result:\n",
    "            dx['fn']=os.path.basename(path)\n",
    "            dx['period']=dx['fn'].split('-')[0]\n",
    "            yield dx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify_all_from_crosstabs().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1600-1624.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1600-1624.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1625-1649.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1625-1649.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1650-1674.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1650-1674.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1675-1699.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1675-1699.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1700-1724.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1700-1724.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1725-1749.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1725-1749.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1750-1774.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1750-1774.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1775-1799.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1775-1799.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1800-1824.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1800-1824.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1825-1849.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1825-1849.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1850-1874.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1850-1874.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1875-1899.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1875-1899.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1900-1924.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1900-1924.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1925-1949.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1925-1949.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1950-1974.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1950-1974.txt\n",
      ">> data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/1975-1999.txt\n",
      ">> saved: data_booknlp/data_by_quarter_century__model_results/1975-1999.txt\n"
     ]
    }
   ],
   "source": [
    "#tools.writegen('data_booknlp/data.classification_probabilities_by_word_by_period.txt', classify_all_from_crosstabs)\n",
    "# last run, V2 (with standardization), 2/4/2019 in the morning\n",
    "\n",
    "#tools.writegen('data_booknlp/data.classification_probabilities_by_word_by_period.V3-b.txt', classify_all_from_crosstabs)\n",
    "# last run, V3 (with rel_word), 2/4/2019 ~19:07\n",
    "# last run, V3-b (with rel_word), 2/4/2019 ~20:20\n",
    "\n",
    "tools.writegen('data_booknlp/data.classification_probabilities_by_word_by_period.V4-b.txt',\n",
    "               classify_all_from_crosstabs,\n",
    "               kwargs={'idir':'data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/'})\n",
    "# last run V4 (with lemma), 2/5 19:04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### 1. Standardization improves meaningfulness\n",
    "\n",
    "Meaningfulness of results seems to have improved with the turn to standardization. Here are the results without standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(\"images/Probability of being a human V1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~vs~**\n",
    "\n",
    "Here are the results with standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(\"images/Probability of being a human V2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Switching to rel_word** doesn't seem to have done much\n",
    "\n",
    "Final form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('images/Probability of being a human [V3].png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 2. There do seem to be interesting trends\n",
    "\n",
    "Like this one. My reading:\n",
    "* (C1) the human-like-ness of ancien regime abstractions *mercy, truth* and *honour* is falling from before or early C18; \n",
    "* (C2) the bourgeois abstractions of *virtue, nation,* and *nature* all have a more enduring human likeness through C18.\n",
    "* (C3) body parts lose and gain personhood in the same pattern as their frequency.\n",
    "    * *Is this meaningful theoretically or is as an artifact of the data?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('images/Sample words in 3-ish clusters (cf graphs above).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which resembles this one on the Agency Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('images/Word Highlighter 3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing features in the model\n",
    "\n",
    "Which words (or rel_words) predict human nouns? Which features are responsible for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_feature_data(idir='data_booknlp/data_by_quarter_century__model_results/'):\n",
    "    for fn in os.listdir(idir):\n",
    "        if not fn.endswith('.txt'): continue\n",
    "        fnfn=os.path.join(idir,fn)\n",
    "        ld=tools.read_ld(fnfn)\n",
    "        for d in ld:\n",
    "            del d['']\n",
    "            d['fn']=fn\n",
    "            d['rel'],d['word']=d['feat'].split('_',1) if '_' in d['feat'] else (d['feat'],d['feat'])\n",
    "            yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_feature_data().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools.writegen('data_booknlp/data.classification_feature_coefficients.txt', synthesize_feature_data)\n",
    "# last run: 2/4/19 21:14\n",
    "\n",
    "tools.writegen('data_booknlp/data.classification_feature_coefficients.txt', synthesize_feature_data)\n",
    "# last run: V4, 2/5/19 12:05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('figures/Subject and object.png',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do (2/4)\n",
    "\n",
    "* Make a better worddb! I want less a million vectors, and more semantic fields (column \"VG\" should have \"Human\", \"Object\", etc). This way I can remove the VG.Human/VG.Object's from the results. (Or I could switch \"X\" to \"X_test\" above.)\n",
    "* Investigate feature loadings. What predicts humanness? Maybe switch features to \"rel_word\". More meaningful that way.\n",
    "* Can we use these features to classify moments of personification 'in real time', i.e. in the text?\n",
    "\n",
    "* **Re-do results with lemmas. (Doing now, rerunning on Sherlock...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring K-means in anthro. index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lit.tools import stats\n",
    "import pandas as pd\n",
    "DFN1 = 'data_booknlp/data.classification_probabilities_by_word_by_period.V4.txt'\n",
    "DFN2 = 'data_booknlp/data.classification_feature_coefficients.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(DFN1,encoding='utf-8',sep='\\t').fillna(0)\n",
    "df1 = df1.loc[df1.word!='who']  # don't konw why this word is causing troubles\n",
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make crosstab\n",
    "df1_pivot=df1.pivot_table(index='word',columns='period',values='ProbClass1', aggfunc='mean')\n",
    "#df1_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to top N words\n",
    "lim_cols=2000\n",
    "df1_pivot = df1_pivot.loc[df1_pivot.abs().sum(axis=1).nlargest(lim_cols).index]\n",
    "df1_pivot = df1_pivot.fillna(0)\n",
    "#df1_pivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> dist(datadf) 2019-02-05 18:32:07\n",
      ">> kmeans(datadf) 2019-02-05 18:32:07\n",
      ">> corr_with_cluster(datadf) 2019-02-05 18:32:09\n",
      ">> regressions(datadf) 2019-02-05 18:32:10\n",
      ">> tsne(datadf) 2019-02-05 18:32:25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmeans_cluster</th>\n",
       "      <th>kmeans_cluster_corr_r</th>\n",
       "      <th>kmeans_cluster_corr_p</th>\n",
       "      <th>polyfit_r^2</th>\n",
       "      <th>polyfit_p</th>\n",
       "      <th>tsne_V2</th>\n",
       "      <th>tsne_V1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998297</td>\n",
       "      <td>1.107433e-18</td>\n",
       "      <td>0.065480</td>\n",
       "      <td>0.643910</td>\n",
       "      <td>49.130215</td>\n",
       "      <td>19.019329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>2</td>\n",
       "      <td>0.898650</td>\n",
       "      <td>2.244702e-06</td>\n",
       "      <td>0.218140</td>\n",
       "      <td>0.201994</td>\n",
       "      <td>46.838520</td>\n",
       "      <td>13.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friend</th>\n",
       "      <td>1</td>\n",
       "      <td>0.459468</td>\n",
       "      <td>7.337861e-02</td>\n",
       "      <td>0.221822</td>\n",
       "      <td>0.195891</td>\n",
       "      <td>-8.251590</td>\n",
       "      <td>11.029244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>2</td>\n",
       "      <td>0.888257</td>\n",
       "      <td>4.320523e-06</td>\n",
       "      <td>0.289684</td>\n",
       "      <td>0.108251</td>\n",
       "      <td>46.509682</td>\n",
       "      <td>13.383260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>9.696761e-19</td>\n",
       "      <td>0.076327</td>\n",
       "      <td>0.596854</td>\n",
       "      <td>48.719574</td>\n",
       "      <td>18.696602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.154243</td>\n",
       "      <td>5.684370e-01</td>\n",
       "      <td>0.139747</td>\n",
       "      <td>0.375899</td>\n",
       "      <td>-11.758357</td>\n",
       "      <td>0.894488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child</th>\n",
       "      <td>2</td>\n",
       "      <td>0.798940</td>\n",
       "      <td>2.054335e-04</td>\n",
       "      <td>0.327660</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>39.280399</td>\n",
       "      <td>-18.826139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>3</td>\n",
       "      <td>0.429084</td>\n",
       "      <td>9.721940e-02</td>\n",
       "      <td>0.619296</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>-14.170627</td>\n",
       "      <td>38.840553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>2</td>\n",
       "      <td>0.994278</td>\n",
       "      <td>5.301309e-15</td>\n",
       "      <td>0.098991</td>\n",
       "      <td>0.507855</td>\n",
       "      <td>47.973133</td>\n",
       "      <td>18.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son</th>\n",
       "      <td>2</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>1.022813e-10</td>\n",
       "      <td>0.160023</td>\n",
       "      <td>0.321912</td>\n",
       "      <td>46.027496</td>\n",
       "      <td>16.695250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother</th>\n",
       "      <td>2</td>\n",
       "      <td>0.983384</td>\n",
       "      <td>8.974634e-12</td>\n",
       "      <td>0.094297</td>\n",
       "      <td>0.525301</td>\n",
       "      <td>45.884205</td>\n",
       "      <td>17.543131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poet</th>\n",
       "      <td>2</td>\n",
       "      <td>0.514920</td>\n",
       "      <td>4.124694e-02</td>\n",
       "      <td>0.821426</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>31.167713</td>\n",
       "      <td>-2.395662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>3</td>\n",
       "      <td>0.918764</td>\n",
       "      <td>5.039960e-07</td>\n",
       "      <td>0.740268</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-37.719227</td>\n",
       "      <td>35.725185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>0</td>\n",
       "      <td>0.525754</td>\n",
       "      <td>3.646729e-02</td>\n",
       "      <td>0.297144</td>\n",
       "      <td>0.101072</td>\n",
       "      <td>7.367354</td>\n",
       "      <td>-12.641108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lover</th>\n",
       "      <td>2</td>\n",
       "      <td>0.794808</td>\n",
       "      <td>2.340965e-04</td>\n",
       "      <td>0.527440</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>36.429081</td>\n",
       "      <td>-2.724204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2</td>\n",
       "      <td>0.583659</td>\n",
       "      <td>1.761589e-02</td>\n",
       "      <td>0.560661</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>34.434067</td>\n",
       "      <td>-5.046004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soldier</th>\n",
       "      <td>2</td>\n",
       "      <td>0.526073</td>\n",
       "      <td>3.633329e-02</td>\n",
       "      <td>0.162676</td>\n",
       "      <td>0.315361</td>\n",
       "      <td>34.242168</td>\n",
       "      <td>16.392660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>0</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>7.559770e-01</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.984468</td>\n",
       "      <td>11.867260</td>\n",
       "      <td>0.109535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>2</td>\n",
       "      <td>0.819052</td>\n",
       "      <td>1.040108e-04</td>\n",
       "      <td>0.374909</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>36.681889</td>\n",
       "      <td>-3.073035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband</th>\n",
       "      <td>2</td>\n",
       "      <td>0.448319</td>\n",
       "      <td>8.157111e-02</td>\n",
       "      <td>0.342446</td>\n",
       "      <td>0.065547</td>\n",
       "      <td>28.802568</td>\n",
       "      <td>-5.312821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daughter</th>\n",
       "      <td>2</td>\n",
       "      <td>0.866066</td>\n",
       "      <td>1.444223e-05</td>\n",
       "      <td>0.311164</td>\n",
       "      <td>0.088665</td>\n",
       "      <td>45.497116</td>\n",
       "      <td>13.508382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whom</th>\n",
       "      <td>3</td>\n",
       "      <td>0.701591</td>\n",
       "      <td>2.454086e-03</td>\n",
       "      <td>0.300089</td>\n",
       "      <td>0.098351</td>\n",
       "      <td>-33.489876</td>\n",
       "      <td>34.779171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444835</td>\n",
       "      <td>8.426099e-02</td>\n",
       "      <td>0.127701</td>\n",
       "      <td>0.411457</td>\n",
       "      <td>0.718401</td>\n",
       "      <td>36.615967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>2</td>\n",
       "      <td>0.595269</td>\n",
       "      <td>1.498628e-02</td>\n",
       "      <td>0.668955</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>31.226246</td>\n",
       "      <td>-17.991108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>1</td>\n",
       "      <td>0.772698</td>\n",
       "      <td>4.496867e-04</td>\n",
       "      <td>0.493304</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>4.025384</td>\n",
       "      <td>24.976799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady</th>\n",
       "      <td>2</td>\n",
       "      <td>0.637974</td>\n",
       "      <td>7.834416e-03</td>\n",
       "      <td>0.665804</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>28.974585</td>\n",
       "      <td>-2.029570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>1</td>\n",
       "      <td>0.734782</td>\n",
       "      <td>1.185792e-03</td>\n",
       "      <td>0.589576</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>-1.038610</td>\n",
       "      <td>31.340946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent</th>\n",
       "      <td>1</td>\n",
       "      <td>0.485396</td>\n",
       "      <td>5.665827e-02</td>\n",
       "      <td>0.158207</td>\n",
       "      <td>0.326463</td>\n",
       "      <td>3.341672</td>\n",
       "      <td>13.672775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stranger</th>\n",
       "      <td>2</td>\n",
       "      <td>0.599112</td>\n",
       "      <td>1.418701e-02</td>\n",
       "      <td>0.487033</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>36.062706</td>\n",
       "      <td>17.973574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1</td>\n",
       "      <td>0.685063</td>\n",
       "      <td>3.406688e-03</td>\n",
       "      <td>0.513741</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>1.738446</td>\n",
       "      <td>39.286953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snare</th>\n",
       "      <td>4</td>\n",
       "      <td>0.388486</td>\n",
       "      <td>1.370060e-01</td>\n",
       "      <td>0.475710</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>-3.116033</td>\n",
       "      <td>-39.927769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gory</th>\n",
       "      <td>1</td>\n",
       "      <td>0.626310</td>\n",
       "      <td>9.437711e-03</td>\n",
       "      <td>0.427489</td>\n",
       "      <td>0.026644</td>\n",
       "      <td>-0.536544</td>\n",
       "      <td>33.412174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stool</th>\n",
       "      <td>0</td>\n",
       "      <td>0.406913</td>\n",
       "      <td>1.177687e-01</td>\n",
       "      <td>0.106731</td>\n",
       "      <td>0.480160</td>\n",
       "      <td>-17.809263</td>\n",
       "      <td>13.172944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonnet</th>\n",
       "      <td>2</td>\n",
       "      <td>0.648025</td>\n",
       "      <td>6.633468e-03</td>\n",
       "      <td>0.164523</td>\n",
       "      <td>0.310867</td>\n",
       "      <td>48.389248</td>\n",
       "      <td>-9.976542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dispute</th>\n",
       "      <td>3</td>\n",
       "      <td>0.553758</td>\n",
       "      <td>2.604719e-02</td>\n",
       "      <td>0.429461</td>\n",
       "      <td>0.026053</td>\n",
       "      <td>-29.834967</td>\n",
       "      <td>18.191807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>censure</th>\n",
       "      <td>3</td>\n",
       "      <td>0.527759</td>\n",
       "      <td>3.563062e-02</td>\n",
       "      <td>0.844160</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-20.817091</td>\n",
       "      <td>28.491804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patent</th>\n",
       "      <td>0</td>\n",
       "      <td>0.298599</td>\n",
       "      <td>2.612757e-01</td>\n",
       "      <td>0.081024</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>-4.814142</td>\n",
       "      <td>-15.036991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woe</th>\n",
       "      <td>4</td>\n",
       "      <td>0.640707</td>\n",
       "      <td>7.492023e-03</td>\n",
       "      <td>0.319252</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>-8.090600</td>\n",
       "      <td>-36.863190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doom</th>\n",
       "      <td>4</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>4.037273e-02</td>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.723519</td>\n",
       "      <td>-17.176155</td>\n",
       "      <td>-30.898794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acre</th>\n",
       "      <td>2</td>\n",
       "      <td>0.552258</td>\n",
       "      <td>2.653969e-02</td>\n",
       "      <td>0.601059</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>34.179485</td>\n",
       "      <td>-0.359453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0</td>\n",
       "      <td>0.481208</td>\n",
       "      <td>5.914723e-02</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>16.457260</td>\n",
       "      <td>-16.486359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>successor</th>\n",
       "      <td>1</td>\n",
       "      <td>0.562711</td>\n",
       "      <td>2.325316e-02</td>\n",
       "      <td>0.174884</td>\n",
       "      <td>0.286647</td>\n",
       "      <td>4.233552</td>\n",
       "      <td>37.969242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wilderness</th>\n",
       "      <td>2</td>\n",
       "      <td>0.647611</td>\n",
       "      <td>6.679854e-03</td>\n",
       "      <td>0.170817</td>\n",
       "      <td>0.295956</td>\n",
       "      <td>46.188538</td>\n",
       "      <td>-25.155376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rack</th>\n",
       "      <td>2</td>\n",
       "      <td>0.554341</td>\n",
       "      <td>2.585793e-02</td>\n",
       "      <td>0.227227</td>\n",
       "      <td>0.187213</td>\n",
       "      <td>35.739899</td>\n",
       "      <td>-12.232049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mirror</th>\n",
       "      <td>3</td>\n",
       "      <td>0.456405</td>\n",
       "      <td>7.556759e-02</td>\n",
       "      <td>0.669257</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>-29.995991</td>\n",
       "      <td>-9.831598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apostle</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.045366</td>\n",
       "      <td>8.675048e-01</td>\n",
       "      <td>0.074798</td>\n",
       "      <td>0.603304</td>\n",
       "      <td>-1.250496</td>\n",
       "      <td>-2.201614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>4</td>\n",
       "      <td>0.901428</td>\n",
       "      <td>1.861915e-06</td>\n",
       "      <td>0.462774</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>-10.772789</td>\n",
       "      <td>-42.625652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fabric</th>\n",
       "      <td>2</td>\n",
       "      <td>0.880430</td>\n",
       "      <td>6.792066e-06</td>\n",
       "      <td>0.021019</td>\n",
       "      <td>0.871028</td>\n",
       "      <td>50.805973</td>\n",
       "      <td>25.145615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>4</td>\n",
       "      <td>0.233365</td>\n",
       "      <td>3.843870e-01</td>\n",
       "      <td>0.238915</td>\n",
       "      <td>0.169557</td>\n",
       "      <td>3.465095</td>\n",
       "      <td>-34.377037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>2</td>\n",
       "      <td>0.558023</td>\n",
       "      <td>2.468600e-02</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>33.848473</td>\n",
       "      <td>-0.681751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigner</th>\n",
       "      <td>0</td>\n",
       "      <td>0.498450</td>\n",
       "      <td>4.939413e-02</td>\n",
       "      <td>0.541475</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>16.111160</td>\n",
       "      <td>-17.522329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draught</th>\n",
       "      <td>4</td>\n",
       "      <td>0.941766</td>\n",
       "      <td>5.216630e-08</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>-10.947495</td>\n",
       "      <td>-41.361042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slide</th>\n",
       "      <td>2</td>\n",
       "      <td>0.544606</td>\n",
       "      <td>2.916237e-02</td>\n",
       "      <td>0.142575</td>\n",
       "      <td>0.367939</td>\n",
       "      <td>48.874413</td>\n",
       "      <td>-9.064995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lie</th>\n",
       "      <td>4</td>\n",
       "      <td>0.349260</td>\n",
       "      <td>1.848620e-01</td>\n",
       "      <td>0.306772</td>\n",
       "      <td>0.092405</td>\n",
       "      <td>7.414455</td>\n",
       "      <td>-31.636488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>badge</th>\n",
       "      <td>2</td>\n",
       "      <td>0.554122</td>\n",
       "      <td>2.592884e-02</td>\n",
       "      <td>0.036548</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>45.536659</td>\n",
       "      <td>-7.131257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weel</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630588</td>\n",
       "      <td>8.822159e-03</td>\n",
       "      <td>0.475178</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>-0.660089</td>\n",
       "      <td>33.058365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyelid</th>\n",
       "      <td>4</td>\n",
       "      <td>0.615479</td>\n",
       "      <td>1.114868e-02</td>\n",
       "      <td>0.389950</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>-30.653116</td>\n",
       "      <td>-23.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handmaid</th>\n",
       "      <td>1</td>\n",
       "      <td>0.643392</td>\n",
       "      <td>7.167353e-03</td>\n",
       "      <td>0.367393</td>\n",
       "      <td>0.050977</td>\n",
       "      <td>2.334065</td>\n",
       "      <td>35.633202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paradise</th>\n",
       "      <td>2</td>\n",
       "      <td>0.549437</td>\n",
       "      <td>2.748469e-02</td>\n",
       "      <td>0.452402</td>\n",
       "      <td>0.019953</td>\n",
       "      <td>31.720003</td>\n",
       "      <td>-7.493086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>4</td>\n",
       "      <td>0.213425</td>\n",
       "      <td>4.273947e-01</td>\n",
       "      <td>0.019692</td>\n",
       "      <td>0.878730</td>\n",
       "      <td>-11.819404</td>\n",
       "      <td>-20.780357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            kmeans_cluster  kmeans_cluster_corr_r  kmeans_cluster_corr_p  \\\n",
       "word                                                                       \n",
       "man                      2               0.998297           1.107433e-18   \n",
       "people                   2               0.898650           2.244702e-06   \n",
       "friend                   1               0.459468           7.337861e-02   \n",
       "woman                    2               0.888257           4.320523e-06   \n",
       "father                   2               0.998329           9.696761e-19   \n",
       "other                    3              -0.154243           5.684370e-01   \n",
       "child                    2               0.798940           2.054335e-04   \n",
       "king                     3               0.429084           9.721940e-02   \n",
       "mother                   2               0.994278           5.301309e-15   \n",
       "son                      2               0.976415           1.022813e-10   \n",
       "brother                  2               0.983384           8.974634e-12   \n",
       "poet                     2               0.514920           4.124694e-02   \n",
       "none                     3               0.918764           5.039960e-07   \n",
       "wife                     0               0.525754           3.646729e-02   \n",
       "lover                    2               0.794808           2.340965e-04   \n",
       "one                      2               0.583659           1.761589e-02   \n",
       "soldier                  2               0.526073           3.633329e-02   \n",
       "god                      0               0.084400           7.559770e-01   \n",
       "sister                   2               0.819052           1.040108e-04   \n",
       "husband                  2               0.448319           8.157111e-02   \n",
       "daughter                 2               0.866066           1.444223e-05   \n",
       "whom                     3               0.701591           2.454086e-03   \n",
       "death                    1               0.444835           8.426099e-02   \n",
       "boy                      2               0.595269           1.498628e-02   \n",
       "country                  1               0.772698           4.496867e-04   \n",
       "lady                     2               0.637974           7.834416e-03   \n",
       "youth                    1               0.734782           1.185792e-03   \n",
       "parent                   1               0.485396           5.665827e-02   \n",
       "stranger                 2               0.599112           1.418701e-02   \n",
       "love                     1               0.685063           3.406688e-03   \n",
       "...                    ...                    ...                    ...   \n",
       "snare                    4               0.388486           1.370060e-01   \n",
       "gory                     1               0.626310           9.437711e-03   \n",
       "stool                    0               0.406913           1.177687e-01   \n",
       "bonnet                   2               0.648025           6.633468e-03   \n",
       "dispute                  3               0.553758           2.604719e-02   \n",
       "censure                  3               0.527759           3.563062e-02   \n",
       "patent                   0               0.298599           2.612757e-01   \n",
       "woe                      4               0.640707           7.492023e-03   \n",
       "doom                     4               0.516828           4.037273e-02   \n",
       "acre                     2               0.552258           2.653969e-02   \n",
       "insult                   0               0.481208           5.914723e-02   \n",
       "successor                1               0.562711           2.325316e-02   \n",
       "wilderness               2               0.647611           6.679854e-03   \n",
       "rack                     2               0.554341           2.585793e-02   \n",
       "mirror                   3               0.456405           7.556759e-02   \n",
       "apostle                  3              -0.045366           8.675048e-01   \n",
       "gem                      4               0.901428           1.861915e-06   \n",
       "fabric                   2               0.880430           6.792066e-06   \n",
       "storm                    4               0.233365           3.843870e-01   \n",
       "bench                    2               0.558023           2.468600e-02   \n",
       "foreigner                0               0.498450           4.939413e-02   \n",
       "draught                  4               0.941766           5.216630e-08   \n",
       "slide                    2               0.544606           2.916237e-02   \n",
       "lie                      4               0.349260           1.848620e-01   \n",
       "badge                    2               0.554122           2.592884e-02   \n",
       "weel                     1               0.630588           8.822159e-03   \n",
       "eyelid                   4               0.615479           1.114868e-02   \n",
       "handmaid                 1               0.643392           7.167353e-03   \n",
       "paradise                 2               0.549437           2.748469e-02   \n",
       "object                   4               0.213425           4.273947e-01   \n",
       "\n",
       "            polyfit_r^2  polyfit_p    tsne_V2    tsne_V1  \n",
       "word                                                      \n",
       "man            0.065480   0.643910  49.130215  19.019329  \n",
       "people         0.218140   0.201994  46.838520  13.268300  \n",
       "friend         0.221822   0.195891  -8.251590  11.029244  \n",
       "woman          0.289684   0.108251  46.509682  13.383260  \n",
       "father         0.076327   0.596854  48.719574  18.696602  \n",
       "other          0.139747   0.375899 -11.758357   0.894488  \n",
       "child          0.327660   0.075741  39.280399 -18.826139  \n",
       "king           0.619296   0.001879 -14.170627  38.840553  \n",
       "mother         0.098991   0.507855  47.973133  18.005348  \n",
       "son            0.160023   0.321912  46.027496  16.695250  \n",
       "brother        0.094297   0.525301  45.884205  17.543131  \n",
       "poet           0.821426   0.000014  31.167713  -2.395662  \n",
       "none           0.740268   0.000156 -37.719227  35.725185  \n",
       "wife           0.297144   0.101072   7.367354 -12.641108  \n",
       "lover          0.527440   0.007655  36.429081  -2.724204  \n",
       "one            0.560661   0.004766  34.434067  -5.046004  \n",
       "soldier        0.162676   0.315361  34.242168  16.392660  \n",
       "god            0.002405   0.984468  11.867260   0.109535  \n",
       "sister         0.374909   0.047166  36.681889  -3.073035  \n",
       "husband        0.342446   0.065547  28.802568  -5.312821  \n",
       "daughter       0.311164   0.088665  45.497116  13.508382  \n",
       "whom           0.300089   0.098351 -33.489876  34.779171  \n",
       "death          0.127701   0.411457   0.718401  36.615967  \n",
       "boy            0.668955   0.000757  31.226246 -17.991108  \n",
       "country        0.493304   0.012046   4.025384  24.976799  \n",
       "lady           0.665804   0.000805  28.974585  -2.029570  \n",
       "youth          0.589576   0.003062  -1.038610  31.340946  \n",
       "parent         0.158207   0.326463   3.341672  13.672775  \n",
       "stranger       0.487033   0.013049  36.062706  17.973574  \n",
       "love           0.513741   0.009218   1.738446  39.286953  \n",
       "...                 ...        ...        ...        ...  \n",
       "snare          0.475710   0.015039  -3.116033 -39.927769  \n",
       "gory           0.427489   0.026644  -0.536544  33.412174  \n",
       "stool          0.106731   0.480160 -17.809263  13.172944  \n",
       "bonnet         0.164523   0.310867  48.389248  -9.976542  \n",
       "dispute        0.429461   0.026053 -29.834967  18.191807  \n",
       "censure        0.844160   0.000006 -20.817091  28.491804  \n",
       "patent         0.081024   0.577400  -4.814142 -15.036991  \n",
       "woe            0.319252   0.082113  -8.090600 -36.863190  \n",
       "doom           0.048570   0.723519 -17.176155 -30.898794  \n",
       "acre           0.601059   0.002546  34.179485  -0.359453  \n",
       "insult         0.697155   0.000425  16.457260 -16.486359  \n",
       "successor      0.174884   0.286647   4.233552  37.969242  \n",
       "wilderness     0.170817   0.295956  46.188538 -25.155376  \n",
       "rack           0.227227   0.187213  35.739899 -12.232049  \n",
       "mirror         0.669257   0.000753 -29.995991  -9.831598  \n",
       "apostle        0.074798   0.603304  -1.250496  -2.201614  \n",
       "gem            0.462774   0.017621 -10.772789 -42.625652  \n",
       "fabric         0.021019   0.871028  50.805973  25.145615  \n",
       "storm          0.238915   0.169557   3.465095 -34.377037  \n",
       "bench          0.637841   0.001358  33.848473  -0.681751  \n",
       "foreigner      0.541475   0.006293  16.111160 -17.522329  \n",
       "draught        0.704545   0.000362 -10.947495 -41.361042  \n",
       "slide          0.142575   0.367939  48.874413  -9.064995  \n",
       "lie            0.306772   0.092405   7.414455 -31.636488  \n",
       "badge          0.036548   0.785047  45.536659  -7.131257  \n",
       "weel           0.475178   0.015138  -0.660089  33.058365  \n",
       "eyelid         0.389950   0.040260 -30.653116 -23.955000  \n",
       "handmaid       0.367393   0.050977   2.334065  35.633202  \n",
       "paradise       0.452402   0.019953  31.720003  -7.493086  \n",
       "object         0.019692   0.878730 -11.819404 -20.780357  \n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_results=stats.analyze_as_dist(df1_pivot,n_kmeans=5)\n",
    "df1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_results.to_csv(DFN1.replace('.txt','.dist_analysis.txt'), sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting nouns and features back together again\n",
    "\n",
    "I'd like to see the nouns and features together: \"dobj_taste\" and \"joy\". Do I use a network? I can put the most upstream form of data into Tableau; or also the summary/crosstab counts. Maybe the crosstab counts, in long/Tableau form, will be what I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pandas as pd\n",
    "\n",
    "def get_most_upstream_data():\n",
    "    # load the giant spreadsheet\n",
    "    booknlp_like_data_fn = 'data_booknlp/data.booknlp_like_data.chadwyck_poetry.lemmatized.txt.gz'\n",
    "    df=pd.read_csv(booknlp_like_data_fn,sep='\\t',encoding='utf-8',quoting=3,error_bad_lines=False)\n",
    "    df['group']=[fn2group.get(fn,'') for fn in df['fn']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['group'].shape, df['group'].loc[df.group!=''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_crosstab_counts_long_form(idir='data_booknlp/data_by_quarter_century__crosstabs__rel_lemma/'):\n",
    "    from scipy.stats import zscore\n",
    "    for fn in sorted(os.listdir(idir)):\n",
    "        if not fn.endswith('.txt'): continue\n",
    "        print '>>',fn,'...'\n",
    "        df_tabs=pd.read_csv(os.path.join(idir,fn),sep='\\t',encoding='utf-8',quoting=3,error_bad_lines=False).fillna('').set_index('word')        \n",
    "        df_tabs_q=df_tabs.select_dtypes('number')\n",
    "        df_tabs_z=df_tabs_q.apply(zscore)\n",
    "        sumval=float(df_tabs_q.sum().sum())\n",
    "        for word in df_tabs.index:\n",
    "            rowd=df_tabs_q.loc[word].to_dict()\n",
    "            row_sum=float(sum(rowd.values()))\n",
    "            for colname,colval in rowd.items():\n",
    "                if not colval: continue\n",
    "                if colname.startswith('_'): continue\n",
    "                colval_fpm=colval/sumval*1000000\n",
    "                colval_z=df_tabs_z.loc[word][colname]\n",
    "                colval_perc_word=colval/row_sum\n",
    "                odx={'fn':fn,'word':word,'feat':colname,'count':colval,'fpm':colval_fpm,'z':colval_z,\n",
    "                    'perc_of_word':colval_perc_word}\n",
    "                yield odx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1600-1624.txt ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count': 1,\n",
       " 'feat': u'nsubj_come',\n",
       " 'fn': '1600-1624.txt',\n",
       " 'fpm': 1.6462585481975116,\n",
       " 'perc_of_word': 0.08333333333333333,\n",
       " 'word': u'a',\n",
       " 'z': 0.17678469709190409}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_crosstab_counts_long_form().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1600-1624.txt ...\n",
      ">> 1625-1649.txt ...\n",
      ">> 1650-1674.txt ...\n",
      ">> 1675-1699.txt ...\n",
      ">> 1700-1724.txt ...\n",
      ">> 1725-1749.txt ...\n",
      ">> 1750-1774.txt ...\n",
      ">> 1775-1799.txt ...\n",
      ">> 1800-1824.txt ...\n",
      ">> 1825-1849.txt ...\n",
      ">> 1850-1874.txt ...\n",
      ">> 1875-1899.txt ...\n",
      ">> 1900-1924.txt ...\n",
      ">> 1925-1949.txt ...\n",
      ">> 1950-1974.txt ...\n",
      ">> 1975-1999.txt ...\n"
     ]
    }
   ],
   "source": [
    "from lit import tools\n",
    "tools.writegen('data_booknlp/data.crosstab_long_form.txt',make_crosstab_counts_long_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
