{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating BookNLP-like data for all nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "I'm working on my personification chapter now. So far I've measured an [\"agency index\"](https://twitter.com/quadrismegistus/status/1059305496211931136), trying to find trends in how words gain/lose (syntactic) \"agency\" over time. This has been interesting, but what's missing is that personifications don't just do things (as the agency index captures), they do *human* things (\"let not Ambition *mock*\") and have *human* things (\"Honour's voice\").\n",
    "\n",
    "So I'm trying to move on from this 'syntax of agency' to a broader 'grammar of personhood'. I took a failed stopover at the 'semantics of personhood' via word2vec: my 'human words' vector didn't end up being that interesting an index for other words, i.e. didn't seem to capture personification effects. Now I'm moving back to the syntactic BookNLP-style data (subject-verb, modifier-noun, etc) I've collected about the nouns for the Chadwyck Healey poetry collections.\n",
    "\n",
    "I'm wondering whether a classifier to separate human vs. non-human (maybe human vs. object) words by way of the distribution of other words ('collocated' by syntax): and then use that classifier to estimate the 'humanness' of all words, not just those in the cross-validation experiment? I did this in a smaller related project on animal stories, and according to the cross-validation results, the model found it easier to separate humans and animals in novels than it did in these anthropomorphic animal stories, which seemed right. But here I want to use a classifier to estimate the humanness of all, even non-human/object words like abstract nouns, to see if that changes over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide an initial set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> streaming as tsv: data.worddb.txt\n",
      "   done [0.6 seconds]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000,\n",
       " [u'fawn',\n",
       "  u'nunnery',\n",
       "  u'woods',\n",
       "  u'spiders',\n",
       "  u'hanging',\n",
       "  u'woody',\n",
       "  u'disobeying',\n",
       "  u'canes',\n",
       "  u'scold',\n",
       "  u'originality'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load words from the project-wide 25K\n",
    "import pandas as pd\n",
    "from lit.tools import read_ld\n",
    "all_words = {d['word'] for d in read_ld('data.worddb.txt')}\n",
    "len(all_words),list(all_words)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform slingshot results into booknlp-like data\n",
    "Code adapted from the classification work in the [Wild Animal Stories notebook](http://localhost:8888/lab/tree/workspace%2Fwildanimalstories%2Fexperiments.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pandas as pd,numpy as np,itertools\n",
    "from lit import tools\n",
    "rels = {\n",
    "        'poss':'Possessive',\n",
    "        'nsubj':'Subject',\n",
    "        'nsubjpass':'Subject (passive)',\n",
    "        'dobj':'Object',\n",
    "        'amod':'Modifier',\n",
    "        'compound':'Modifier',\n",
    "        'appos':'Modifier',\n",
    "        'attr':'Modifier',\n",
    "        'dative':'Object'\n",
    "       }\n",
    "\n",
    "PATH_TO_SLINGSHOT_RESULT_DATA = '../syntax/results_slingshot/spacy_syntax/parse_path2/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_results(fn=PATH_TO_SLINGSHOT_RESULT_DATA):\n",
    "    import pandas as pd,os\n",
    "    from mpi_slingshot import stream_results\n",
    "    for path,data in stream_results(fn):\n",
    "        if '.ipynb' in path: continue\n",
    "        sent_ld=[]\n",
    "        num_sent=0\n",
    "        fn=os.path.split(path)[-1]\n",
    "        for dx in data:\n",
    "            if sent_ld and dx['sent_start']!=sent_ld[-1]['sent_start']:\n",
    "                old=get_booknlp_like_data(sent_ld)\n",
    "                num_sent+=1\n",
    "                for odx in old:\n",
    "                    odx['num_sent']=num_sent\n",
    "                    odx['fn']=fn\n",
    "                    yield odx\n",
    "                    sent_ld=[]\n",
    "            sent_ld+=[dx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_booknlp_like_data(sent_ld,pos_only={'NOUN'},lemma=False):\n",
    "    \"\"\"\n",
    "    Modifiers\n",
    "    Nouns possessed by characters: poss\n",
    "    Adjectives modifying characters: \n",
    "    Verbs of which character is a subject\n",
    "    Verbs of which character is an object\n",
    "    \n",
    "    rels = {'poss':'Possessive',\n",
    "           'nsubj':'Subject',\n",
    "           'dobj':'Object',\n",
    "           'amod':'Modifier'}\n",
    "    \"\"\"\n",
    "    \n",
    "    old=[]\n",
    "    for dx in sent_ld:\n",
    "        word=dx['lemma'] if lemma else dx['word']\n",
    "        rel=dx['dep']\n",
    "        head=dx['head_lemma'] if lemma else dx['head']\n",
    "        pos=dx['pos']\n",
    "        word,head=word.lower(),head.lower()\n",
    "        if not word in all_words or not pos in pos_only: continue\n",
    "        word_dx={'head':head,'word':word,'rel':rel}\n",
    "        old+=[word_dx]\n",
    "    return old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ran this on Sherlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterator\n",
    "transformer = transform_results(PATH_TO_SLINGSHOT_RESULT_DATA)\n",
    "#pd.DataFrame(list(itertools.islice(transformer,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools.writegen('./data.booknlp_like_data.chadwyck_poetry.txt', transform_results)\n",
    "# last run: 2/3/2019 13:49 PST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloaded this data (*data.booknlp_like_data.chadwyck_poetry.txt.gz*) to *data_booknlp/*\n",
    "\n",
    "Data appears as:\n",
    "\n",
    "| fn             | head     | num_sent | rel      | word      |\n",
    "|----------------|----------|----------|----------|-----------|\n",
    "| Z400605772.xml | are      | 1        | nsubj    | hills     |\n",
    "| Z400605772.xml | knows    | 2        | dobj     | roads     |\n",
    "| Z400605772.xml | knows    | 2        | conj     | moves     |\n",
    "| Z400605772.xml | in       | 3        | pobj     | circles   |\n",
    "| Z400605772.xml | within   | 3        | pobj     | head      |\n",
    "| Z400605772.xml | has      | 4        | dobj     | say       |\n",
    "| Z400605772.xml | is       | 5        | nsubj    | river     |\n",
    "| Z400605772.xml | lie      | 5        | nsubj    | winds     |\n",
    "| Z400605772.xml | at       | 6        | pobj     | dawn      |\n",
    "| Z400605772.xml | sees     | 6        | dobj     | skies     |\n",
    "| Z400605772.xml | feels    | 7        | nsubj    | shadows   |\n",
    "| Z400605772.xml | of       | 7        | pobj     | night     |\n",
    "| Z400605772.xml | recline  | 7        | dobj     | fingers   |\n",
    "| Z400605772.xml | on       | 7        | pobj     | eyes      |\n",
    "| Z400605772.xml | welcomes | 8        | dobj     | sun       |\n",
    "| Z400605772.xml | sun      | 8        | conj     | rain      |\n",
    "| Z400605772.xml | has      | 9        | nsubj    | landscape |\n",
    "| Z400605772.xml | has      | 9        | dobj     | depth     |\n",
    "| Z400605772.xml | depth    | 9        | conj     | height    |\n",
    "| Z400605772.xml | city     | 10       | ROOT     | city      |\n",
    "| Z400605772.xml | burns    | 10       | compound | passion   |\n",
    "| Z400605772.xml | like     | 10       | pobj     | burns     |\n",
    "| Z400605772.xml | walks    | 11       | compound | morning   |\n",
    "| Z400605772.xml | of       | 11       | pobj     | walks     |\n",
    "| Z400605772.xml | on       | 11       | pobj     | wave      |\n",
    "| Z400605772.xml | of       | 11       | pobj     | sand      |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
